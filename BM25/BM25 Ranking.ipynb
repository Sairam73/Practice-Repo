{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef4e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from stemming.porter2 import stem\n",
    "import glob\n",
    "import string\n",
    "import math\n",
    " \n",
    "class Rcv1Doc:\n",
    "    def __init__(self, docID): #initialization\n",
    "        self.docID = docID\n",
    "        self.terms = {}\n",
    "        self.doc_len = 0\n",
    "    def get_doc_id(self):\n",
    "        return self.docID\n",
    "    def add_term(self, term):\n",
    "        stemmed_term = self.stem_term(term)\n",
    "        if stemmed_term not in self.terms:\n",
    "            self.terms[stemmed_term] = 1\n",
    "        else:\n",
    "            self.terms[stemmed_term] += 1\n",
    "        self.doc_len += 1\n",
    "    def stem_term(self, term):\n",
    "        return stem(term)\n",
    "\n",
    "def parse_rcv1v2(stop_words, inputpath):\n",
    "    collection = {}\n",
    "    os.chdir(inputpath)\n",
    "    for file_ in glob.glob(\"*.xml\"):  #iterates through all xml files in the path\n",
    "        docID = None\n",
    "        text = \"\"\n",
    "        start_end = False\n",
    "        for line in open(file_):        #reads each line of xml file \n",
    "            line = line.strip()\n",
    "            if not start_end:\n",
    "                if line.startswith(\"<newsitem \"):\n",
    "                    for part in line.split():\n",
    "                        if part.startswith(\"itemid=\"):\n",
    "                            docID = part.split(\"=\")[1].split(\"\\\"\")[1]       #gets docID\n",
    "                            break  \n",
    "                if line.startswith(\"<text>\"):\n",
    "                    start_end = True  \n",
    "            elif line.startswith(\"</text>\"):\n",
    "                break\n",
    "            else:\n",
    "                line = line.replace(\"<p>\", \"\").replace(\"</p>\", \"\")\n",
    "                line = line.translate(str.maketrans('', '', string.digits)).translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "                for term in line.split():\n",
    "                    term = stem(term.lower())            #applying stemming and converting to lower case\n",
    "                    if len(term) > 2 and term not in stop_words:\n",
    "                        if docID:\n",
    "                            if docID not in collection:\n",
    "                                doc = Rcv1Doc(docID)\n",
    "                                collection[docID] = doc\n",
    "                            collection[docID].add_term(term)\n",
    "                            text += term + \" \"\n",
    " \n",
    "        if docID:\n",
    "            print(\"Document ID:\", docID)\n",
    "            print(\"Term Frequencies:\", collection[docID].terms)\n",
    " \n",
    "    return collection\n",
    " \n",
    "def parse_query(query0, stop_words):\n",
    "    \n",
    "    query_terms = {} # Initialize a dictionary to store term frequencies\n",
    "    words = query0.translate(str.maketrans('', '', string.punctuation)).split()    # Remove punctuation characters from the query text and tokenize it\n",
    "    for word in words:    # For loop to process each word from the query\n",
    "        word = word.lower()\n",
    "        if word not in stop_words and word.isalpha() and word.strip(): # Checks if the word is not a stop word, is alphabetic, and is not an empty string\n",
    "            stemmed_word = stem(word)\n",
    "            if stemmed_word in query_terms:\n",
    "                query_terms[stemmed_word] += 1\n",
    "            else:\n",
    "                query_terms[stemmed_word] = 1\n",
    "    return query_terms\n",
    " \n",
    "def read_stop_words(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        stop_words = file.read().split(',')\n",
    "    return stop_words \n",
    "\n",
    "def avg_length(coll):\n",
    "    total_doc_length = sum(doc.doc_len for doc in coll)\n",
    "    return total_doc_length / len(coll) if len(coll) > 0 else 0\n",
    "\n",
    "def my_bm25(coll, q, df):\n",
    "    bm25_scores = {}\n",
    "    N = len(coll)\n",
    "    avg_len = avg_length(coll)\n",
    "    k1 = 1.2\n",
    "    k2 = 100\n",
    "    b = 0.75\n",
    "    \n",
    "    query_terms = parse_query(q, stop_words)\n",
    "    \n",
    "    for doc in coll:\n",
    "        docid = doc.get_doc_id()\n",
    "        fi = doc.doc_len\n",
    "        score = 0.0\n",
    "        \n",
    "        for term in query_terms:\n",
    "            if term in doc.terms:\n",
    "                ni = df.get(term, 0)\n",
    "                r_i = 0  # Assuming R = ri = 0\n",
    "                R = 0\n",
    "                # BM25 score calculation\n",
    "                part1 = ((r_i+0.5)/(R-r_i+0.5))/((ni - r_i + 0.5) / (N - ni - r_i + 0.5))\n",
    "                part2 = (k1 + 1) * fi / (k1 * ((1 - b) + b * (fi / avg_len)) + fi)\n",
    "                part3 = (k2 + 1) * query_terms.get(term, 0) / (k2 + query_terms.get(term, 0))\n",
    "                \n",
    "                score += math.log(part1 * part2 * part3)      #using math library from python to calculate log\n",
    "        \n",
    "        bm25_scores[docid] = score\n",
    "    \n",
    "    return bm25_scores\n",
    "\n",
    "def main():\n",
    "    inputpath = r'C:\\Users\\0703s\\OneDrive - Queensland University of Technology\\QUT\\IFN 647 TEXT WEB MEDIA ANALYTICS\\Assignment 1\\RCV1v2'\n",
    "    output_file = \"Sairam_Panneerselvam_Q3.txt\"  \n",
    "    \n",
    "    Index = []\n",
    "    os.chdir(inputpath)\n",
    "    \n",
    "    for file_path in glob.glob(os.path.join(inputpath, '*.xml')):\n",
    "        with open(file_path, 'r', encoding='utf-8') as xml_file:\n",
    "            xml_content = xml_file.read()\n",
    "        \n",
    "        docid = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        \n",
    "        start_tag = '<text>'\n",
    "        end_tag = '</text>'\n",
    "        start_index = xml_content.find(start_tag)    # Extract text content from XML\n",
    "        end_index = xml_content.find(end_tag)\n",
    "        \n",
    "        if start_index != -1 and end_index != -1:\n",
    "            text_content = xml_content[start_index + len(start_tag):end_index]\n",
    "            text_content = text_content.translate(str.maketrans('', '', string.digits)).translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "            terms = [term for term in text_content.split() if len(term) > 2]\n",
    "            \n",
    "            doc = Rcv1Doc(docid)\n",
    "            for term in terms:\n",
    "                doc.add_term(term)\n",
    "            \n",
    "            Index.append(doc)\n",
    "    \n",
    "    df = {}\n",
    "    for doc in Index:\n",
    "        for term in doc.terms:\n",
    "            if term in df:\n",
    "                df[term] += 1\n",
    "            else:\n",
    "                df[term] = 1\n",
    "    \n",
    "    queries = [\"The British-Fashion Awards\", \"Rocket attacks\", \"Broadcast Fashion Awards\", \"stock market\"]\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "\n",
    "        for query in queries:        # Ranking results for all queries\n",
    "            print(f\"The query is: {query}\", file=f)\n",
    "            print(f\"The following are the BM25 score for each document:\", file=f)\n",
    "            bm25_scores = my_bm25(Index, query, df)\n",
    "            for docid, score in bm25_scores.items():\n",
    "                doc_len = next(doc.doc_len for doc in Index if doc.get_doc_id() == docid)\n",
    "                print(f\"Document ID: {docid}, Doc Length: {doc_len} -- BM25 Score: {score}\", file=f)\n",
    "            print(\"\", file=f)  \n",
    "        \n",
    "        for query in queries:         # Top 6 results for each query\n",
    "            print(f\"For query '{query}', the top-6 possible relevant documents are:\", file=f)\n",
    "            bm25_scores = my_bm25(Index, query, df)\n",
    "            sorted_docs_top6 = sorted(bm25_scores.items(), key=lambda x: x[1], reverse=True)[:6]\n",
    "            for docid, score in sorted_docs_top6:\n",
    "                doc_len = next(doc.doc_len for doc in Index if doc.get_doc_id() == docid)\n",
    "                print(f\"Document ID: {docid}, Doc Length: {doc_len} -- BM25 Score: {score}\", file=f)\n",
    "            print(\"\", file=f)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
